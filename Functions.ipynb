{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2352f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_grayscale(img):\n",
    "    # Check if the image is already in grayscale\n",
    "    if len(img.shape) == 2:\n",
    "        return img\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    grayscale_img = np.zeros_like(img[..., 0])  # Create an empty grayscale image\n",
    "    \n",
    "    # Iterate over each pixel and calculate the grayscale value\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            b, g, r = img[i, j]  # Get the BGR values of the pixel\n",
    "            gray_value = int(0.299 * r + 0.587 * g + 0.114 * b)  # Calculate the grayscale value\n",
    "            grayscale_img[i, j] = gray_value  # Assign the grayscale value to the corresponding pixel\n",
    "    \n",
    "    return grayscale_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2217b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_otsu_threshold(gray_image):\n",
    "    # Calculate histogram\n",
    "    hist = cv2.calcHist([gray_image], [0], None, [256], [0,256])\n",
    "    hist_norm = hist.ravel() / hist.sum()\n",
    "    # Calculate probabilities\n",
    "    q = np.cumsum(hist_norm)\n",
    "    bins = np.arange(256)\n",
    "\n",
    "    # Initialize variables\n",
    "    fn_min = np.inf\n",
    "    thresh = -1\n",
    "    # Iterate through all thresholds to find optimal one\n",
    "    for i in range(1, 256):\n",
    "        p1, p2 = np.hsplit(hist_norm, [i]) # probabilities\n",
    "        q1, q2 = q[i], q[255] - q[i] # cum sum of classes\n",
    "        b1, b2 = np.hsplit(bins, [i]) # weights\n",
    "\n",
    "        # Skip calculation if q1 or q2 is zero\n",
    "        if q1 == 0 or q2 == 0:\n",
    "            continue\n",
    "\n",
    "        # Finding means and variances\n",
    "        m1, m2 = np.sum(p1 * b1) / q1, np.sum(p2 * b2) / q2\n",
    "        v1, v2 = np.sum(((b1 - m1) ** 2) * p1) / q1, np.sum(((b2 - m2) ** 2) * p2) / q2\n",
    "\n",
    "        # Calculate the minimum within-class variance\n",
    "        fn = v1 * q1 + v2 * q2\n",
    "        if fn < fn_min:\n",
    "            fn_min = fn\n",
    "            thresh = i\n",
    "\n",
    "    # Binarize image\n",
    "    ret, bin_img = cv2.threshold(gray_image, thresh, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    return ret, bin_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3b750d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_dilate(binary_image, kernel, iterations=1):\n",
    "    # Define the dimensions of the kernel\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "    \n",
    "    # Get the dimensions of the input image\n",
    "    image_height, image_width = binary_image.shape\n",
    "    \n",
    "    # Initialize an empty image to store the dilated result\n",
    "    dilated_image = np.zeros_like(binary_image)\n",
    "    \n",
    "    # Pad the input image on all sides to handle edge cases\n",
    "    padded_image = np.pad(binary_image, ((kernel_height//2, kernel_height//2), (kernel_width//2, kernel_width//2)), mode='constant', constant_values=0)\n",
    "    \n",
    "    # Iterate through each pixel in the padded image\n",
    "    for i in range(image_height):\n",
    "        for j in range(image_width):\n",
    "            # Extract the region of interest (ROI) from the padded image using the kernel\n",
    "            roi = padded_image[i:i+kernel_height, j:j+kernel_width]\n",
    "            \n",
    "            # Perform element-wise AND operation between the kernel and the ROI\n",
    "            # If any pixel in the ROI is non-zero, set the corresponding pixel in the dilated image to 255\n",
    "            if np.sum(roi & kernel) > 0:\n",
    "                dilated_image[i, j] = 255\n",
    "    \n",
    "    # If iterations > 1, perform dilation repeatedly\n",
    "    if iterations > 1:\n",
    "        for _ in range(iterations - 1):\n",
    "            dilated_image = manual_dilate(dilated_image, kernel, iterations=1)\n",
    "    \n",
    "    return dilated_image\n",
    "\n",
    "\n",
    "def euclidean_distance_transform(bin_img):\n",
    "    # Pad the binary image with zeros\n",
    "    padded_img = np.pad(bin_img, 1, mode='constant', constant_values=0)\n",
    "\n",
    "    # Initialize the output distance transform image\n",
    "    distance_img = np.zeros_like(padded_img, dtype=np.float32)\n",
    "\n",
    "    # Define the kernel for 3x3 neighborhood\n",
    "    kernel = np.array([[1, 1, 1],\n",
    "                       [1, 1, 1],\n",
    "                       [1, 1, 1]])\n",
    "\n",
    "    # Iterate over each pixel in the padded image\n",
    "    for i in range(1, padded_img.shape[0] - 1):\n",
    "        for j in range(1, padded_img.shape[1] - 1):\n",
    "            if padded_img[i, j] == 0:  # Background pixel\n",
    "                # Compute Euclidean distance\n",
    "                dist = np.sqrt(np.sum((kernel * distance_img[i-1:i+2, j-1:j+2])**2))\n",
    "                distance_img[i, j] = dist\n",
    "\n",
    "    # Remove the padding to get the original size\n",
    "    distance_img = distance_img[1:-1, 1:-1]\n",
    "\n",
    "    return distance_img\n",
    "\n",
    "def threshold_manual(dist_transform):\n",
    "    # Calculate the threshold value\n",
    "    threshold_value = 0.001 * np.max(dist_transform)\n",
    "    \n",
    "    # Apply the threshold manually\n",
    "    thresholded_image = np.where(dist_transform > threshold_value, 255, 0).astype(np.uint8)\n",
    "\n",
    "    return threshold_value, thresholded_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e0a63a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def connected_components_labeling_manual(image):\n",
    "    # Initialize labels matrix\n",
    "    labels = np.zeros_like(image)\n",
    "    label_count = 1  # Start label count from 1, as 0 is reserved for background\n",
    "\n",
    "    # Define dictionary to track equivalence between labels\n",
    "    equivalence = {}\n",
    "\n",
    "    # First pass\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            if image[i, j] == 255:\n",
    "                neighbors = []\n",
    "                if i > 0:\n",
    "                    neighbors.append(labels[i - 1, j])\n",
    "                if j > 0:\n",
    "                    neighbors.append(labels[i, j - 1])\n",
    "\n",
    "                if len(neighbors) == 0:\n",
    "                    labels[i, j] = label_count\n",
    "                    label_count += 1\n",
    "                else:\n",
    "                    min_neighbor = min(neighbors)\n",
    "                    labels[i, j] = min_neighbor\n",
    "                    for neighbor in neighbors:\n",
    "                        if neighbor != min_neighbor:\n",
    "                            equivalence[neighbor] = min_neighbor\n",
    "\n",
    "    # Second pass - Apply equivalence\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            if labels[i, j] != 0:\n",
    "                parent_label = labels[i, j]\n",
    "                while parent_label in equivalence:\n",
    "                    parent_label = equivalence[parent_label]\n",
    "                labels[i, j] = parent_label\n",
    "\n",
    "    # Count the number of connected components\n",
    "    unique_labels = np.unique(labels)\n",
    "    num_components = len(unique_labels) - 1  # Subtract 1 for the background label\n",
    "\n",
    "    return num_components, labels\n",
    "\n",
    "# Example usage:\n",
    "# num_components_manual, labeled_image_manual = connected_components_labeling_manual(sure_fg)\n",
    "\n",
    "#You're correct; the simple manual implementation provided may not yield the same results as OpenCV's cv2.connectedComponents() function due to its simplified approach. OpenCV's implementation is more complex and optimized for accuracy and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97573805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def watershed_manual(image, markers):\n",
    "    # Initialize labels matrix\n",
    "    labels = np.copy(markers)\n",
    "\n",
    "    # Define queue for pixels to process\n",
    "    queue = []\n",
    "\n",
    "    # Define neighborhood kernel\n",
    "    kernel = np.array([[1, 1, 1],\n",
    "                       [1, 1, 1],\n",
    "                       [1, 1, 1]])\n",
    "\n",
    "    # Add marker pixels to the queue\n",
    "    for i in range(markers.shape[0]):\n",
    "        for j in range(markers.shape[1]):\n",
    "            if markers[i, j] == -1:\n",
    "                queue.append((i, j))\n",
    "                labels[i, j] = 0\n",
    "\n",
    "    # Process pixels in the queue\n",
    "    while queue:\n",
    "        # Get pixel coordinates from the queue\n",
    "        i, j = queue.pop(0)\n",
    "\n",
    "        # Explore neighbors\n",
    "        for di in range(-1, 2):\n",
    "            for dj in range(-1, 2):\n",
    "                ni, nj = i + di, j + dj\n",
    "                if 0 <= ni < image.shape[0] and 0 <= nj < image.shape[1]:\n",
    "                    if labels[ni, nj] == -1:\n",
    "                        labels[ni, nj] = labels[i, j]\n",
    "                        queue.append((ni, nj))\n",
    "\n",
    "    # Compute image gradients\n",
    "    gradient_x = np.gradient(image)[0]\n",
    "    gradient_y = np.gradient(image)[1]\n",
    "\n",
    "    # Compute gradient magnitude\n",
    "    gradient_magnitude = np.sqrt(gradient_x ** 2 + gradient_y ** 2)\n",
    "\n",
    "    # Find local minima in gradient magnitude\n",
    "    local_minima = np.zeros_like(gradient_magnitude, dtype=bool)\n",
    "    for i in range(1, gradient_magnitude.shape[0] - 1):\n",
    "        for j in range(1, gradient_magnitude.shape[1] - 1):\n",
    "            neighbors = gradient_magnitude[i - 1:i + 2, j - 1:j + 2]\n",
    "            local_minima[i, j] = np.all(gradient_magnitude[i, j] <= neighbors)\n",
    "\n",
    "    # Get coordinates where local_minima is True\n",
    "    minima_coords = np.where(local_minima)\n",
    "\n",
    "    # Assign -1 to labels where local_minima is True\n",
    "    labels[minima_coords[0], minima_coords[1]] = -1\n",
    "     \n",
    "    return labels\n",
    "\n",
    "# Example usage:\n",
    "# watershed_result = watershed_manual(img, markers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b581eda4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
